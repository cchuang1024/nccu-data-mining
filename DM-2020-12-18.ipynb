{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "## 為什麼要降維\n",
    "\n",
    "1. curse of dimensionality\n",
    "2. 維度過高會降低分類品質\n",
    "3. 為了效果，也為了效率\n",
    "\n",
    "## 另一方面思考\n",
    "\n",
    "> 降維會失真，為何為幫助效果呢?\n",
    "\n",
    "1. 可能資料本來就不需要那麼多維度，降維是找出它有意義的 feature\n",
    "\n",
    "## 常見方法\n",
    "\n",
    "1. PCA - Priciple Component Analysis\n",
    "2. \n",
    "\n",
    "## PCA\n",
    "\n",
    "1. 線性代數的技術\n",
    "2. 針對連續性數值的 attribute\n",
    "3. 希望可以找到新的 attribute，是原本 attribute 的 combination\n",
    "4. 新的 attribute 是 orthorgonal\n",
    "5. 希望找到 variation (變異數) 最大的那維\n",
    "6. \n",
    "\n",
    "### eigenvector & eigenvalue\n",
    "\n",
    "若 A 為一 n * n 矩陣，存在 x 使得 $Ax = \\lambda x$\n",
    "\n",
    "則 x 為 eignevector，$\\lambda$ 為 eigenvalue\n",
    "\n",
    "## app\n",
    "\n",
    "1. eigen-face\n",
    "2. KL-Transform\n",
    "\n",
    "## 作用\n",
    "\n",
    "1. 抓出資料最重要的特徵\n",
    "2. 去除資料的 noise\n",
    "3. 用較少的特徵來代表大多數的資料\n",
    "\n",
    "## Singular Value Decomposition\n",
    "\n",
    "> Latent Semantic Analysis\n",
    "\n",
    "1. synonomy: 在 NLP 中，原本是以 vector space model 進行分維，這樣不考慮同義詞的情況，會導致 recall 很低\n",
    "2. ploysemy: vector space model 也無法處理多義詞，會導致 precision 低\n",
    "3. 早期同義詞用 wordnet，中文用 hownet\n",
    "4. 後來提出 singular value decomposition\n",
    "\n",
    "### Singular Value Decomposition\n",
    "\n",
    "1. 把 m * n 矩陣轉成三個矩陣\n",
    "2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
